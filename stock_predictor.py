# -*- coding: utf-8 -*-
"""DataAnalytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SQqp0FKJid3LcI12BafwOzW5qg67LdGx
"""

!pip install tensorflow-gpu

import math
import numpy as np
import time
import sqlite3
import os
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM

def trainData( stockData, stockName):
    training_data_len = math.ceil(len(stockData) * .8)

    # Scale the data == normalization
    scaled_data = scaler.fit_transform(stockData)

    # Create the training dataset
    # Create the scaled training data set
    train_data = scaled_data[0:training_data_len, :]
    # Split data into x_train and y_train
    x_train = []  # training features
    y_train = []  # target variables
    for i in range(60, len(train_data)):
        x_train.append(train_data[i - 60:i, 0])
        y_train.append(train_data[i, 0])

    # Convert x_train and y_train to numpy arrays
    x_train, y_train = np.array(x_train), np.array(y_train)

    # Reshape the data 2d to 3d
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

    # Build the LSTM model
    model = Sequential()
    model.add(LSTM(50, return_sequences=True,
                   input_shape=(x_train.shape[1], 1)))
    model.add(LSTM(50, return_sequences=False))
    model.add(Dense(50))
    model.add(Dense(1))

    # Compile the model
    model.compile(optimizer='adam', loss='mean_squared_error')

    # Train model
    model.fit(x_train, y_train, batch_size=1, epochs=1)
    # Save Model
    models[stockName] = model

def getValidationRMSE( stockData, stockName):
    # Create the testing data set
    # Create a new array containing scaled values from index 1542 to 2003
    scaled_data = scaler.fit_transform(stockData)
    training_data_len = math.ceil(len(stockData) * .8)
    test_data = scaled_data[training_data_len - 60:, :]

    # Create the data sets x+test and y_test
    x_test = []
    y_test = stockData[training_data_len:, :]

    for i in range(60, len(test_data)):
        x_test.append(test_data[i - 60:i, 0])

    # Convert the data to numpy array
    x_test = np.array(x_test)

    # Reshape data
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

    # Get models predicted price values
    predictions = models[stockName].predict(x_test)
    predictions = scaler.inverse_transform(predictions)

    # Get the root mean squared error (RMSE)
    rmse = np.sqrt(np.mean(predictions - y_test) ** 2)
    return rmse

def predictPrice( stockData, stockName):
    # Predict the closing price for date X
    # Get the last 6- entries closing price and values and convert the dataframe
    # to an array
    last_60_entries = stockData[-60:]
    # Scale the data to be values between 0 an 1
    last_60_entries_scaled = scaler.transform(last_60_entries)
    # create empty list
    X_test = []
    # Append last 60 entries
    X_test.append(last_60_entries_scaled)
    X_test = np.array(X_test)
    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
    # Get predicted scaled price
    pred_price = models[stockName].predict(X_test)
    # undo the scaling
    pred_price = scaler.inverse_transform(pred_price)
    return pred_price[0][0]

def train( stockData, stockName, lastPrice):
    trainData(stockData, stockName)
    rmse = getValidationRMSE(stockData, stockName)
    price = predictPrice(stockData, stockName)
    if lastPrice > price:
        writePredictionToDatabase(price, rmse, int(
            time.time()), stockName, 'decrease')
    else:
        writePredictionToDatabase(price, rmse, int(
            time.time()), stockName, 'increase')

def predictStocks( stockNameList):
    try:
        for stockName in stockNameList:
            print(stockName)
            stockData = getFromDatabaseAsNumpy(stockName, 'PRICE')
            if len(stockData) > 60:
                lastPrice = stockData[-1][0]
                print('LAST PRice', lastPrice)
                train(stockData, stockName, lastPrice)
    except:
        pass


def getFromDatabaseAsNumpy( stockName, attribute):
    cur = conn.cursor()
    cur.execute("SELECT {0} FROM {1}".format(attribute, stockName))
    rows = cur.fetchall()
    return np.array(rows)

def writePredictionToDatabase( stockPrice, rmse, date, table, effect):
    print(table, stockPrice, effect)
    data = (table, float(stockPrice), rmse, date, effect)
    cur = conn.cursor()
    sql = '''INSERT INTO PREDICTIONS (SYMBOL, PRICE, RMSE, DATEOFPRICE, EFFECT) VALUES (?,?,?,?,?);'''
    cur.execute(sql, data)
    conn.commit()

def main():
    # stocks = ['BAC', 'EOD', 'C', 'SAN', 'HSBC', 'MUFG',
    #           'ITUB', 'GS', 'SMFG', 'MS', 'BUD', 'KO', 'FMX', 'CRH', 'LYB', 'ORCL', 'SAP', 'DELL', 'HPQ', 'CAJ', 'HPE',
    #           'CAT', 'DE', 'BAM', 'AXP', 'SNE', 'HON', 'INT', 'DIS', 'ADM', 'BG', 'TSN', 'KR', 'WMT', 'TGT', 'M', 'UNH',
    #           'ANTM', 'CNC', 'HUM', 'CI', 'HCA', 'FMS', 'CVS', 'PG', 'UL', 'GE', 'ABB', 'JCI', 'IBM', 'CAN', 'PUK',
    #           'MFC', 'BRKB', 'AIG', 'ALL', 'CB', 'PGR', 'BABA', 'UPS', 'FDX', 'ABT', 'MDT', 'MT', 'PKX', 'ACH', 'NUE',
    #           'RIO', 'COP', 'VALE', 'MMM', 'TM', 'F', 'GM', 'HMC', 'TTM', 'MGA', 'NOK', 'SLB', 'SIN', 'RDS-A', 'BP',
    #           'XOM', 'TOT', 'CVX', 'PSX', 'VLO', 'MPC', 'PBR', 'E', 'ABBV', 'ET', 'ENB', 'PAGP', 'TSM', 'HD', 'LOW',
    #           'BBY', 'TJX', 'DG', 'T', 'VZ', 'CHL', 'CCZ', 'CHA', 'TEF', 'AMX', 'ORAN', 'BTI', 'PM', 'ARW', 'SYY',
    #           'MCK', 'ABC', 'CAH']
    predictStocks(stocks)

models = {}
conn = sqlite3.connect('stocks.db')
conn.execute(
    '''CREATE TABLE IF NOT EXISTS PREDICTIONS (SYMBOL TEXT NOT NULL, PRICE REAL NOT NULL, RMSE REAL NOT NULL, DATEOFPRICE INTEGER NOT NULL, EFFECT TEXT);''')
scaler = MinMaxScaler(feature_range=(0, 1))

main()